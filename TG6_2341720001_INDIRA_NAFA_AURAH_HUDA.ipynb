{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNjA+8djfjgg2qZD5m4Nm2y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Indiranafa/Machine-Learning/blob/main/TG6_2341720001_INDIRA_NAFA_AURAH_HUDA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**PRAKTIKUM 1**"
      ],
      "metadata": {
        "id": "VcKniet9vMQS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AUIy8gIPuzSx"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install annoy"
      ],
      "metadata": {
        "id": "Dc-_ndb2vO5j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "\n",
        "from annoy import AnnoyIndex\n",
        "\n",
        "# 1. Dataset 2D\n",
        "np.random.seed(42)\n",
        "n_points = 1000\n",
        "X = np.random.rand(n_points, 2) * 100  # titik random dalam ruang 100x100\n",
        "\n",
        "# Query point (ambil salah satu titik random)\n",
        "query = X[np.random.randint(0, n_points)]\n",
        "\n",
        "# 2. Exact NN (brute force)\n",
        "start = time.time()\n",
        "distances = np.linalg.norm(X - query, axis=1)\n",
        "idx_exact = np.argsort(distances)[:3]  # ambil 3 terdekat\n",
        "time_exact = time.time() - start\n",
        "\n",
        "print(\"Exact NN index:\", idx_exact)\n",
        "print(\"Exact NN jarak:\", distances[idx_exact])\n",
        "print(\"Waktu Exact:\", round(time_exact*1000, 4), \"ms\")\n",
        "\n",
        "# 3. Annoy NN (3 tree)\n",
        "f = 2  # dimensi\n",
        "t = AnnoyIndex(f, 'euclidean')\n",
        "for i, vec in enumerate(X):\n",
        "    t.add_item(i, vec)\n",
        "\n",
        "t.build(3)  # 3 trees\n",
        "\n",
        "start = time.time()\n",
        "idx_ann = t.get_nns_by_vector(query, 3)  # cari 3 NN\n",
        "time_ann = time.time() - start\n",
        "\n",
        "print(\"\\nAnnoy NN index:\", idx_ann)\n",
        "print(\"Annoy NN jarak:\", [np.linalg.norm(X[i]-query) for i in idx_ann])\n",
        "print(\"Waktu Annoy:\", round(time_ann*1000, 4), \"ms\")\n",
        "\n",
        "# 4. Visualisasi hasil\n",
        "plt.figure(figsize=(6,6))\n",
        "plt.scatter(X[:,0], X[:,1], c=\"lightgray\", s=20, label=\"Dataset\")\n",
        "plt.scatter(query[0], query[1], c=\"red\", marker=\"x\", s=100, label=\"Query\")\n",
        "\n",
        "# Exact NN ditandai biru\n",
        "plt.scatter(X[idx_exact,0], X[idx_exact,1], c=\"blue\", s=80, label=\"Exact NN\")\n",
        "\n",
        "# Annoy NN ditandai hijau\n",
        "plt.scatter(X[idx_ann,0], X[idx_ann,1], c=\"green\", s=50, marker=\"s\", label=\"Annoy NN\")\n",
        "\n",
        "plt.legend()\n",
        "plt.title(\"Exact NN vs Annoy NN (3 trees)\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "mgJTxIUHvXTr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(42)\n",
        "n_points = 1000\n",
        "X = np.random.rand(n_points, 2) * 100\n",
        "query = X[np.random.randint(0, n_points)]\n",
        "\n",
        "start = time.time()\n",
        "distances = np.linalg.norm(X - query, axis=1)\n",
        "idx_exact = np.argsort(distances)[:3]\n",
        "time_exact = time.time() - start\n",
        "\n",
        "f = 2\n",
        "t = AnnoyIndex(f, 'euclidean')\n",
        "for i, vec in enumerate(X):\n",
        "    t.add_item(i, vec)\n",
        "t.build(8)\n",
        "\n",
        "start = time.time()\n",
        "idx_ann = t.get_nns_by_vector(query, 3)\n",
        "time_ann = time.time() - start\n",
        "\n",
        "print(\"Euclidean (8 tree, 1000 data)\")\n",
        "print(\"Exact NN:\", idx_exact)\n",
        "print(\"Annoy NN:\", idx_ann)\n",
        "print(\"Waktu (Exact vs Annoy):\", round(time_exact*1000, 4), \",\", round(time_ann*1000, 4), \"ms\")"
      ],
      "metadata": {
        "id": "F8ZXUsyIva18"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(42)\n",
        "n_points = 100000\n",
        "X = np.random.rand(n_points, 2) * 100\n",
        "query = X[np.random.randint(0, n_points)]\n",
        "\n",
        "start = time.time()\n",
        "distances = np.linalg.norm(X - query, axis=1)\n",
        "idx_exact = np.argsort(distances)[:3]\n",
        "time_exact = time.time() - start\n",
        "\n",
        "f = 2\n",
        "t = AnnoyIndex(f, 'euclidean')\n",
        "for i, vec in enumerate(X):\n",
        "    t.add_item(i, vec)\n",
        "t.build(3)\n",
        "\n",
        "start = time.time()\n",
        "idx_ann = t.get_nns_by_vector(query, 3)\n",
        "time_ann = time.time() - start\n",
        "\n",
        "print(\"Euclidean (3 tree, 100000 data)\")\n",
        "print(\"Exact NN:\", idx_exact)\n",
        "print(\"Annoy NN:\", idx_ann)\n",
        "print(\"Waktu (Exact vs Annoy):\", round(time_exact*1000, 4), \",\", round(time_ann*1000, 4), \"ms\")"
      ],
      "metadata": {
        "id": "LdcL1sOFvdGa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(42)\n",
        "n_points = 1000\n",
        "X = np.random.rand(n_points, 2) * 100\n",
        "query = X[np.random.randint(0, n_points)]\n",
        "\n",
        "start = time.time()\n",
        "distances = np.linalg.norm(X - query, axis=1)\n",
        "idx_exact = np.argsort(distances)[:3]\n",
        "time_exact = time.time() - start\n",
        "\n",
        "f = 2\n",
        "t = AnnoyIndex(f, 'angular')\n",
        "for i, vec in enumerate(X):\n",
        "    t.add_item(i, vec)\n",
        "t.build(3)\n",
        "\n",
        "start = time.time()\n",
        "idx_ann = t.get_nns_by_vector(query, 3)\n",
        "time_ann = time.time() - start\n",
        "\n",
        "print(\"Angular (3 tree, 1000 data)\")\n",
        "print(\"Exact NN:\", idx_exact)\n",
        "print(\"Annoy NN:\", idx_ann)\n",
        "print(\"Waktu (Exact vs Annoy):\", round(time_exact*1000, 4), \",\", round(time_ann*1000, 4), \"ms\")"
      ],
      "metadata": {
        "id": "poiIX8nivfV0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(42)\n",
        "n_points = 1000\n",
        "X = np.random.rand(n_points, 2) * 100\n",
        "query = X[np.random.randint(0, n_points)]\n",
        "\n",
        "start = time.time()\n",
        "distances = np.linalg.norm(X - query, axis=1)\n",
        "idx_exact = np.argsort(distances)[:3]\n",
        "time_exact = time.time() - start\n",
        "\n",
        "f = 2\n",
        "t = AnnoyIndex(f, 'angular')\n",
        "for i, vec in enumerate(X):\n",
        "    t.add_item(i, vec)\n",
        "t.build(8)\n",
        "\n",
        "start = time.time()\n",
        "idx_ann = t.get_nns_by_vector(query, 3)\n",
        "time_ann = time.time() - start\n",
        "\n",
        "print(\"Angular (8 tree, 1000 data)\")\n",
        "print(\"Exact NN:\", idx_exact)\n",
        "print(\"Annoy NN:\", idx_ann)\n",
        "print(\"Waktu (Exact vs Annoy):\", round(time_exact*1000, 4), \",\", round(time_ann*1000, 4), \"ms\")"
      ],
      "metadata": {
        "id": "3mwv6j0ovhN6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(42)\n",
        "n_points = 100000\n",
        "X = np.random.rand(n_points, 2) * 100\n",
        "query = X[np.random.randint(0, n_points)]\n",
        "\n",
        "start = time.time()\n",
        "distances = np.linalg.norm(X - query, axis=1)\n",
        "idx_exact = np.argsort(distances)[:3]\n",
        "time_exact = time.time() - start\n",
        "\n",
        "f = 2\n",
        "t = AnnoyIndex(f, 'angular')\n",
        "for i, vec in enumerate(X):\n",
        "    t.add_item(i, vec)\n",
        "t.build(3)\n",
        "\n",
        "start = time.time()\n",
        "idx_ann = t.get_nns_by_vector(query, 3)\n",
        "time_ann = time.time() - start\n",
        "\n",
        "print(\"Angular (3 tree, 100000 data)\")\n",
        "print(\"Exact NN:\", idx_exact)\n",
        "print(\"Annoy NN:\", idx_ann)\n",
        "print(\"Waktu (Exact vs Annoy):\", round(time_exact*1000, 4), \",\", round(time_ann*1000, 4), \"ms\")"
      ],
      "metadata": {
        "id": "iyuVDMFGvjNb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === PRAKTIKUM 1: Exact NN vs ANNOY (Otomatis) ===\n",
        "!pip install annoy -q\n",
        "\n",
        "import numpy as np\n",
        "import time\n",
        "import pandas as pd\n",
        "from annoy import AnnoyIndex\n",
        "\n",
        "# Fungsi untuk menjalankan 1 percobaan\n",
        "def run_experiment(metric, n_trees, n_points):\n",
        "    np.random.seed(42)\n",
        "    X = np.random.rand(n_points, 2) * 100\n",
        "    query = X[np.random.randint(0, n_points)]\n",
        "\n",
        "    # --- Exact NN (brute force) ---\n",
        "    start = time.time()\n",
        "    distances = np.linalg.norm(X - query, axis=1)\n",
        "    idx_exact = np.argsort(distances)[:3]\n",
        "    time_exact = time.time() - start\n",
        "\n",
        "    # --- Annoy NN ---\n",
        "    f = 2\n",
        "    t = AnnoyIndex(f, metric)\n",
        "    for i, vec in enumerate(X):\n",
        "        t.add_item(i, vec)\n",
        "    t.build(n_trees)\n",
        "\n",
        "    start = time.time()\n",
        "    idx_ann = t.get_nns_by_vector(query, 3)\n",
        "    time_ann = time.time() - start\n",
        "\n",
        "    return {\n",
        "        \"Distance Metrics\": metric.capitalize(),\n",
        "        \"Tree\": n_trees,\n",
        "        \"Jumlah data\": n_points,\n",
        "        \"Hasil Index terdekat ENN vs ANN\": f\"{idx_exact.tolist()}, {idx_ann}\",\n",
        "        \"Waktu komputasi Vs (ms)\": f\"{round(time_exact*1000,4)} , {round(time_ann*1000,4)}\"\n",
        "    }\n",
        "\n",
        "# === Jalankan semua percobaan ===\n",
        "experiments = [\n",
        "    (\"euclidean\", 3, 1000),\n",
        "    (\"euclidean\", 8, 1000),\n",
        "    (\"euclidean\", 3, 100000),\n",
        "    (\"angular\", 3, 1000),\n",
        "    (\"angular\", 8, 1000),\n",
        "    (\"angular\", 3, 100000),\n",
        "]\n",
        "\n",
        "results = [run_experiment(*exp) for exp in experiments]\n",
        "\n",
        "# === Tampilkan hasil dalam tabel ===\n",
        "df_results = pd.DataFrame(results)\n",
        "print(\"\\n=== HASIL PERCOBAAN EXACT NN vs ANNOY ===\\n\")\n",
        "display(df_results)"
      ],
      "metadata": {
        "id": "qZmQDRevvlvE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install annoy -q\n",
        "import numpy as np\n",
        "import time\n",
        "import pandas as pd\n",
        "from sklearn.metrics.pairwise import euclidean_distances\n",
        "from annoy import AnnoyIndex\n",
        "\n",
        "def spotify_experiment(metric='euclidean', n_trees=8, n_tracks=1_000_000, n_features=20):\n",
        "    np.random.seed(42)\n",
        "    print(f\"\\n=== Metric: {metric}, Trees: {n_trees}, Data: {n_tracks} ===\")\n",
        "\n",
        "    # ---- 1. Dataset mirip Spotify ----\n",
        "    X = np.random.rand(n_tracks, n_features).astype(np.float32)\n",
        "    query = np.random.rand(1, n_features).astype(np.float32)\n",
        "\n",
        "    # ---- 2. Exact NN (brute force) ----\n",
        "    start = time.time()\n",
        "    distances = euclidean_distances(query, X)[0]\n",
        "    exact_idx = np.argsort(distances)[:5]\n",
        "    exact_time = time.time() - start\n",
        "\n",
        "    # ---- 3. Approx NN (Annoy) ----\n",
        "    f = n_features\n",
        "    annoy_index = AnnoyIndex(f, metric)\n",
        "    for i in range(n_tracks):\n",
        "        annoy_index.add_item(i, X[i])\n",
        "    annoy_index.build(n_trees)\n",
        "\n",
        "    start = time.time()\n",
        "    annoy_idx = annoy_index.get_nns_by_vector(query[0], 5)\n",
        "    annoy_time = time.time() - start\n",
        "\n",
        "    print(\"Exact NN result:\", exact_idx)\n",
        "    print(\"Annoy NN result:\", annoy_idx)\n",
        "    print(\"Waktu (Exact vs Annoy):\", round(exact_time, 3), \"s ,\", round(annoy_time, 3), \"s\")\n",
        "\n",
        "    return {\n",
        "        \"Distance Metrics\": metric.capitalize(),\n",
        "        \"Tree\": n_trees,\n",
        "        \"Jumlah data\": n_tracks,\n",
        "        \"Hasil Index terdekat ENN vs ANN\": f\"{exact_idx.tolist()}, {annoy_idx}\",\n",
        "        \"Waktu komputasi Vs (s)\": f\"{round(exact_time,3)} , {round(annoy_time,3)}\"\n",
        "    }\n",
        "\n",
        "# Jalankan dua percobaan (seperti di tabel modul)\n",
        "results_spotify = [\n",
        "    spotify_experiment('euclidean', 8, 1_000_000),\n",
        "    spotify_experiment('angular', 8, 1_000_000)\n",
        "]\n",
        "\n",
        "# Tampilkan hasil dalam tabel\n",
        "df_spotify = pd.DataFrame(results_spotify)\n",
        "print(\"\\n=== HASIL SIMULASI SPOTIFY ===\")\n",
        "display(df_spotify)"
      ],
      "metadata": {
        "id": "ArsjWlx1vst2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import time\n",
        "from sklearn.metrics.pairwise import euclidean_distances\n",
        "from annoy import AnnoyIndex\n",
        "\n",
        "# ---- 1. Buat dataset mirip Spotify ----\n",
        "n_tracks = 1_000_000     # 1 juta track (modul mencontohkan 50 juta)\n",
        "n_features = 20           # contoh fitur: danceability, energy, tempo, dll\n",
        "\n",
        "# dataset besar (random untuk simulasi)\n",
        "X = np.random.rand(n_tracks, n_features).astype(np.float32)\n",
        "\n",
        "# query track (misalnya lagu baru)\n",
        "query = np.random.rand(1, n_features).astype(np.float32)\n",
        "\n",
        "# ---- 2. Exact NN (brute force) ----\n",
        "start = time.time()\n",
        "distances = euclidean_distances(query, X)[0]    # hitung semua jarak\n",
        "exact_idx = np.argsort(distances)[:5]           # ambil 5 lagu terdekat\n",
        "exact_time = time.time() - start\n",
        "\n",
        "print(\"Exact NN result:\", exact_idx)\n",
        "print(\"Exact NN time:\", round(exact_time, 3), \"seconds\")\n",
        "\n",
        "# ---- 3. Approx NN pakai Annoy ----\n",
        "f = n_features\n",
        "annoy_index = AnnoyIndex(f, 'euclidean')  # pakai Euclidean metric\n",
        "n_trees = 8                               # jumlah tree untuk indexing\n",
        "\n",
        "# build index (tidak dihitung waktu build-nya)\n",
        "for i in range(n_tracks):\n",
        "    annoy_index.add_item(i, X[i])\n",
        "\n",
        "annoy_index.build(n_trees)\n",
        "\n",
        "# proses pencarian (hanya dihitung waktu query-nya)\n",
        "start = time.time()\n",
        "annoy_idx = annoy_index.get_nns_by_vector(query[0], 5)  # cari 5 lagu mirip\n",
        "annoy_time = time.time() - start\n",
        "\n",
        "print(\"\\nAnnoy result:\", annoy_idx)\n",
        "print(\"Annoy time:\", round(annoy_time, 3), \"seconds\")"
      ],
      "metadata": {
        "id": "_j7818iDvueK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import time\n",
        "import pandas as pd\n",
        "from sklearn.metrics.pairwise import euclidean_distances\n",
        "from annoy import AnnoyIndex\n",
        "\n",
        "# ---- 1. Buat dataset mirip Spotify ----\n",
        "n_tracks = 1_000_000     # 1 juta track\n",
        "n_features = 20           # fitur: danceability, energy, tempo, dll\n",
        "\n",
        "# dataset besar (random untuk simulasi)\n",
        "X = np.random.rand(n_tracks, n_features).astype(np.float32)\n",
        "query = np.random.rand(1, n_features).astype(np.float32)\n",
        "\n",
        "# ---- 2. Exact NN (brute force) ----\n",
        "start = time.time()\n",
        "distances = euclidean_distances(query, X)[0]\n",
        "exact_idx = np.argsort(distances)[:5]\n",
        "exact_time = time.time() - start\n",
        "\n",
        "# ---- 3. Approx NN pakai Annoy (Euclidean) ----\n",
        "f = n_features\n",
        "annoy_index = AnnoyIndex(f, 'euclidean')\n",
        "n_trees = 8\n",
        "\n",
        "for i in range(n_tracks):\n",
        "    annoy_index.add_item(i, X[i])\n",
        "annoy_index.build(n_trees)\n",
        "\n",
        "start = time.time()\n",
        "annoy_idx_euclidean = annoy_index.get_nns_by_vector(query[0], 5)\n",
        "annoy_time_euclidean = time.time() - start\n",
        "\n",
        "# ---- 4. Approx NN pakai Annoy (Angular) ----\n",
        "annoy_index_angular = AnnoyIndex(f, 'angular')\n",
        "\n",
        "for i in range(n_tracks):\n",
        "    annoy_index_angular.add_item(i, X[i])\n",
        "annoy_index_angular.build(n_trees)\n",
        "\n",
        "start = time.time()\n",
        "annoy_idx_angular = annoy_index_angular.get_nns_by_vector(query[0], 5)\n",
        "annoy_time_angular = time.time() - start\n",
        "\n",
        "# ---- 5. Tampilkan hasil dalam tabel ----\n",
        "data_hasil = {\n",
        "    \"Distance Metrics\": [\"Euclidean\", \"Angular\"],\n",
        "    \"Tree\": [8, 8],\n",
        "    \"Jumlah data\": [1_000_000, 1_000_000],\n",
        "    \"Hasil Index terdekat ENN vs ANN\": [\n",
        "        f\"{list(exact_idx)}, {list(annoy_idx_euclidean)}\",\n",
        "        f\"{list(exact_idx)}, {list(annoy_idx_angular)}\"\n",
        "    ],\n",
        "    \"Waktu komputasi Vs (s)\": [\n",
        "        f\"{round(exact_time, 3)} , {round(annoy_time_euclidean, 3)}\",\n",
        "        f\"{round(exact_time, 3)} , {round(annoy_time_angular, 3)}\"\n",
        "    ]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data_hasil)\n",
        "print(df.to_markdown(index=False))"
      ],
      "metadata": {
        "id": "1QxS3tw1v-i0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\"Kenapa code di bagian build index tidak dihitung waktunya?\" Karena tujuan percobaan adalah membandingkan waktu pencarian (query time), bukan waktu membangun struktur data indeks."
      ],
      "metadata": {
        "id": "z8Zs4475wIr2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**PRAKTIKUM 2**"
      ],
      "metadata": {
        "id": "UXLoiyNywLKP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install faiss-cpu\n",
        "#!pip install faiss-gpu"
      ],
      "metadata": {
        "id": "pHQIubSnwH_E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import faiss\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "\n",
        "# 1. Buat dataset 2D sederhana\n",
        "np.random.seed(42)\n",
        "X = np.random.rand(1000, 2).astype('float32')  # 1000 titik 2D\n",
        "query = np.array([[0.5, 0.5]], dtype='float32')  # query di tengah\n",
        "\n",
        "# 2. Exact NN dengan IndexFlatL2 (brute force tapi cepat)\n",
        "index_flat = faiss.IndexFlatL2(2)   # L2 = Euclidean distance\n",
        "index_flat.add(X)\n",
        "\n",
        "start = time.time()\n",
        "D_flat, I_flat = index_flat.search(query, 3)  # cari 3 tetangga terdekat\n",
        "end = time.time()\n",
        "time_flat = end - start\n",
        "\n",
        "# 3. IVF + PQ (Approximate)\n",
        "nlist = 10   # jumlah cluster (inverted list)\n",
        "m = 2        # berapa subvector untuk product quantization\n",
        "quantizer = faiss.IndexFlatL2(2)   # dipakai IVF untuk cluster awal\n",
        "index_ivfpq = faiss.IndexIVFPQ(quantizer, 2, nlist, m, 8)  # 8 bit per subvector\n",
        "\n",
        "index_ivfpq.train(X)  # training centroid\n",
        "index_ivfpq.add(X)\n",
        "\n",
        "start = time.time()\n",
        "D_ivfpq, I_ivfpq = index_ivfpq.search(query, 3)\n",
        "end = time.time()\n",
        "time_ivfpq = end - start\n",
        "\n",
        "# 4. Print hasil\n",
        "print(\"Exact NN (Flat) indices:\", I_flat, \"distances:\", D_flat)\n",
        "print(\"IVF+PQ indices:\", I_ivfpq, \"distances:\", D_ivfpq)\n",
        "print(\"Waktu Exact:\", time_flat)\n",
        "print(\"Waktu IVF+PQ:\", time_ivfpq)\n",
        "\n",
        "# 5. Visualisasi\n",
        "plt.scatter(X[:,0], X[:,1], alpha=0.4, label=\"Dataset\")\n",
        "plt.scatter(query[:,0], query[:,1], c='red', marker='*', s=200, label=\"Query\")\n",
        "\n",
        "# Tetangga dari Flat\n",
        "plt.scatter(X[I_flat[0],0], X[I_flat[0],1], c='blue', s=100, edgecolor='k', label=\"Exact NN\")\n",
        "\n",
        "# Tetangga dari IVF+PQ\n",
        "plt.scatter(X[I_ivfpq[0],0], X[I_ivfpq[0],1], c='green', marker='x', s=100, label=\"IVF+PQ NN\")\n",
        "\n",
        "plt.legend()\n",
        "plt.title(\"Perbandingan Exact NN vs FAISS IVF+PQ\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "LXO_3QJWwS8C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import faiss\n",
        "import time\n",
        "import pandas as pd\n",
        "\n",
        "def run_faiss_experiment(metric, dim, n_data):\n",
        "    np.random.seed(42)\n",
        "    X = np.random.rand(n_data, dim).astype('float32')\n",
        "    query = np.random.rand(1, dim).astype('float32')\n",
        "\n",
        "    # --- Exact NN (Flat) ---\n",
        "    if metric == 'euclidean':\n",
        "        index_flat = faiss.IndexFlatL2(dim)\n",
        "    else:\n",
        "        index_flat = faiss.IndexFlatIP(dim)\n",
        "\n",
        "    index_flat.add(X)\n",
        "\n",
        "    start = time.time()\n",
        "    D_flat, I_flat = index_flat.search(query, 3)\n",
        "    time_flat = time.time() - start\n",
        "\n",
        "    # --- Approx NN (IVF+PQ) ---\n",
        "    nlist = 10\n",
        "    # pastikan m (jumlah subquantizer) membagi dim\n",
        "    for m in range(dim, 0, -1):\n",
        "        if dim % m == 0 and m <= 8:\n",
        "            break\n",
        "\n",
        "    if metric == 'euclidean':\n",
        "        quantizer = faiss.IndexFlatL2(dim)\n",
        "        index_ivfpq = faiss.IndexIVFPQ(quantizer, dim, nlist, m, 8)\n",
        "    else:\n",
        "        quantizer = faiss.IndexFlatIP(dim)\n",
        "        index_ivfpq = faiss.IndexIVFPQ(quantizer, dim, nlist, m, 8, faiss.METRIC_INNER_PRODUCT)\n",
        "\n",
        "    index_ivfpq.train(X)\n",
        "    index_ivfpq.add(X)\n",
        "\n",
        "    start = time.time()\n",
        "    D_ivfpq, I_ivfpq = index_ivfpq.search(query, 3)\n",
        "    time_ivfpq = time.time() - start\n",
        "\n",
        "    return {\n",
        "        \"Metric\": metric.capitalize(),\n",
        "        \"Dimensi\": f\"{dim}D\",\n",
        "        \"Jumlah Data\": n_data,\n",
        "        \"Hasil ENN vs ANN\": f\"{I_flat[0].tolist()} , {I_ivfpq[0].tolist()}\",\n",
        "        \"Waktu (s)\": f\"{round(time_flat, 4)} , {round(time_ivfpq, 4)}\"\n",
        "    }\n",
        "\n",
        "# Jalankan semua variasi percobaan\n",
        "results = []\n",
        "for metric in ['euclidean', 'inner_product']:\n",
        "    for dim in [2, 5]:\n",
        "        for n_data in [1000, 1000000]:\n",
        "            print(f\"Running: Metric={metric}, Dim={dim}, Data={n_data}\")\n",
        "            results.append(run_faiss_experiment(metric, dim, n_data))\n",
        "\n",
        "# Tampilkan hasil dalam bentuk tabel\n",
        "df = pd.DataFrame(results)\n",
        "print(\"\\n=== HASIL PERCOBAAN PRAKTIKUM 2 (FAISS) ===\")\n",
        "print(df.to_string(index=False))"
      ],
      "metadata": {
        "id": "q7I6MJrdwWsZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**PRAKTIKUM 3**"
      ],
      "metadata": {
        "id": "kdQTPA7EwdFj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install hnswlib"
      ],
      "metadata": {
        "id": "z6oLX4B6wfAL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import hnswlib\n",
        "import numpy as np\n",
        "import time\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "# ===========================\n",
        "# 1. Buat data 2D acak\n",
        "# ===========================\n",
        "num_elements = 1000\n",
        "dim = 2\n",
        "data = np.random.random((num_elements, dim)).astype(np.float32)\n",
        "\n",
        "# Query point\n",
        "query = np.array([[0.5, 0.5]], dtype=np.float32)\n",
        "k = 5  # cari 5 tetangga terdekat\n",
        "\n",
        "# ===========================\n",
        "# 2. Exact NN (Brute Force)\n",
        "# ===========================\n",
        "nn = NearestNeighbors(n_neighbors=k, algorithm='brute', metric='euclidean')\n",
        "nn.fit(data)\n",
        "\n",
        "start = time.time()\n",
        "distances, indices = nn.kneighbors(query)\n",
        "end = time.time()\n",
        "\n",
        "print(\"=== Exact NN ===\")\n",
        "print(\"Indices:\", indices)\n",
        "print(\"Distances:\", distances)\n",
        "print(\"Waktu:\", end - start, \"detik\")\n",
        "\n",
        "# ===========================\n",
        "# 3. HNSW\n",
        "# ===========================\n",
        "# Inisialisasi index HNSW\n",
        "p = hnswlib.Index(space='l2', dim=dim)\n",
        "\n",
        "# Ukuran maksimum elemen yang bisa ditampung\n",
        "p.init_index(max_elements=num_elements, ef_construction=100, M=16)\n",
        "\n",
        "# Tambahkan data\n",
        "p.add_items(data)\n",
        "\n",
        "# Set parameter pencarian\n",
        "p.set_ef(50)   # tradeoff speed vs accuracy\n",
        "\n",
        "start = time.time()\n",
        "labels, distances = p.knn_query(query, k=k)\n",
        "end = time.time()\n",
        "\n",
        "print(\"\\n=== HNSW ===\")\n",
        "print(\"Indices:\", labels)\n",
        "print(\"Distances:\", distances)\n",
        "print(\"Waktu:\", end - start, \"detik\")"
      ],
      "metadata": {
        "id": "21qdoJ5MwmqB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install library jika belum ada\n",
        "!pip install hnswlib scikit-learn\n",
        "\n",
        "import hnswlib\n",
        "import numpy as np\n",
        "import time\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "# ========================================\n",
        "# Fungsi percobaan untuk berbagai kondisi\n",
        "# ========================================\n",
        "def run_experiment(num_elements, dim, metric):\n",
        "    print(f\"\\n=== Percobaan: {num_elements} data, {dim}D, metric={metric} ===\")\n",
        "\n",
        "    # 1. Buat data random\n",
        "    data = np.random.random((num_elements, dim)).astype(np.float32)\n",
        "    query = np.random.random((1, dim)).astype(np.float32)\n",
        "    k = 5\n",
        "\n",
        "    # ---------------------------\n",
        "    # Exact NN (Brute Force)\n",
        "    # ---------------------------\n",
        "    nn = NearestNeighbors(n_neighbors=k, algorithm='brute', metric=metric)\n",
        "    nn.fit(data)\n",
        "    start = time.time()\n",
        "    distances_nn, indices_nn = nn.kneighbors(query)\n",
        "    waktu_nn = time.time() - start\n",
        "\n",
        "    # ---------------------------\n",
        "    # HNSW (hnswlib)\n",
        "    # ---------------------------\n",
        "    space = 'l2' if metric == 'euclidean' else 'ip'  # 'ip' (inner product) bisa dipakai alternatif\n",
        "    p = hnswlib.Index(space=space, dim=dim)\n",
        "    p.init_index(max_elements=num_elements, ef_construction=100, M=16)\n",
        "    p.add_items(data)\n",
        "    p.set_ef(50)\n",
        "\n",
        "    start = time.time()\n",
        "    labels, distances_hnsw = p.knn_query(query, k=k)\n",
        "    waktu_hnsw = time.time() - start\n",
        "\n",
        "    # ---------------------------\n",
        "    # Tampilkan hasil ringkas\n",
        "    # ---------------------------\n",
        "    print(\"Exact NN waktu:\", round(waktu_nn, 6), \"detik\")\n",
        "    print(\"HNSW waktu:\", round(waktu_hnsw, 6), \"detik\")\n",
        "    print(\"Selisih:\", round(waktu_nn - waktu_hnsw, 6), \"detik\\n\")\n",
        "\n",
        "    return {\n",
        "        'jumlah_data': num_elements,\n",
        "        'dimensi': dim,\n",
        "        'metric': metric,\n",
        "        'waktu_ExactNN': waktu_nn,\n",
        "        'waktu_HNSW': waktu_hnsw\n",
        "    }\n",
        "\n",
        "# ========================================\n",
        "# Jalankan semua kombinasi percobaan\n",
        "# ========================================\n",
        "hasil = []\n",
        "for metric in ['euclidean', 'manhattan']:\n",
        "    for dim in [2, 5]:\n",
        "        for num in [1000, 1_000_000]:\n",
        "            hasil.append(run_experiment(num, dim, metric))\n",
        "\n",
        "# ========================================\n",
        "# Buat tabel hasil\n",
        "# ========================================\n",
        "import pandas as pd\n",
        "df = pd.DataFrame(hasil)\n",
        "print(\"\\n=== Tabel Hasil Percobaan ===\")\n",
        "display(df)"
      ],
      "metadata": {
        "id": "uAatlqHnw0VC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kode pada percobaan ini digunakan untuk membandingkan kinerja antara metode Exact Nearest Neighbor (Brute Force) dan HNSW (Hierarchical Navigable Small World) dengan berbagai kondisi data. Program ini membuat dataset acak dengan variasi jumlah data yaitu 1000 dan 1 juta titik, serta dimensi data 2D dan 5D. Selain itu, digunakan juga dua jenis metric distance yaitu Euclidean dan Manhattan untuk mengukur jarak antar titik. Pada bagian Exact NN, algoritma menghitung jarak semua titik terhadap query secara langsung sehingga memerlukan waktu lebih lama, sedangkan HNSW menggunakan struktur graf untuk mempercepat pencarian tetangga terdekat. Waktu komputasi dari masing-masing metode dicatat agar dapat dibandingkan. Hasil akhirnya ditampilkan dalam bentuk tabel yang memperlihatkan pengaruh dimensi, ukuran data, dan jenis metric terhadap waktu proses kedua metode tersebut."
      ],
      "metadata": {
        "id": "x9oPS8u0w40j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**PRAKTIKUM 4**"
      ],
      "metadata": {
        "id": "SG2SIdQPw9Ii"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import time\n",
        "from annoy import AnnoyIndex\n",
        "import faiss\n",
        "import hnswlib\n",
        "\n",
        "# ===============================\n",
        "# 1. Buat dataset 1 juta data 5D\n",
        "# ===============================\n",
        "n_data = 1_000_000   # bisa coba 100_000 dulu jika RAM terbatas\n",
        "dim = 5\n",
        "X = np.random.random((n_data, dim)).astype(np.float32)\n",
        "\n",
        "# Query point\n",
        "query = np.random.random((1, dim)).astype(np.float32)\n",
        "k = 10\n",
        "\n",
        "# ===============================\n",
        "# 2. Annoy\n",
        "# ===============================\n",
        "print(\"=== Annoy ===\")\n",
        "ann_index = AnnoyIndex(dim, 'euclidean')\n",
        "\n",
        "start = time.time()\n",
        "for i in range(n_data):\n",
        "    ann_index.add_item(i, X[i])\n",
        "ann_index.build(10)  # 10 trees\n",
        "build_time = time.time() - start\n",
        "\n",
        "start = time.time()\n",
        "neighbors = ann_index.get_nns_by_vector(query[0], k, include_distances=True)\n",
        "query_time = time.time() - start\n",
        "\n",
        "print(\"Build time:\", build_time, \"detik\")\n",
        "print(\"Query time:\", query_time, \"detik\")\n",
        "print(\"Neighbors:\", neighbors[0][:5], \"...\")\n",
        "\n",
        "# ===============================\n",
        "# 3. FAISS (Flat Index)\n",
        "# ===============================\n",
        "print(\"\\n=== FAISS (IndexFlatL2) ===\")\n",
        "faiss_index = faiss.IndexFlatL2(dim)\n",
        "\n",
        "start = time.time()\n",
        "faiss_index.add(X)\n",
        "build_time = time.time() - start\n",
        "\n",
        "start = time.time()\n",
        "distances, indices = faiss_index.search(query, k)\n",
        "query_time = time.time() - start\n",
        "\n",
        "print(\"Build time:\", build_time, \"detik\")\n",
        "print(\"Query time:\", query_time, \"detik\")\n",
        "print(\"Neighbors:\", indices[0][:5], \"...\")\n",
        "\n",
        "# ===============================\n",
        "# 4. HNSW (hnswlib)\n",
        "# ===============================\n",
        "print(\"\\n=== HNSW (hnswlib) ===\")\n",
        "hnsw_index = hnswlib.Index(space='l2', dim=dim)\n",
        "\n",
        "start = time.time()\n",
        "hnsw_index.init_index(max_elements=n_data, ef_construction=200, M=16)\n",
        "hnsw_index.add_items(X)\n",
        "build_time = time.time() - start\n",
        "\n",
        "hnsw_index.set_ef(50)\n",
        "\n",
        "start = time.time()\n",
        "labels, distances = hnsw_index.knn_query(query, k=k)\n",
        "query_time = time.time() - start\n",
        "\n",
        "print(\"Build time:\", build_time, \"detik\")\n",
        "print(\"Query time:\", query_time, \"detik\")\n",
        "print(\"Neighbors:\", labels[0][:5], \"...\")"
      ],
      "metadata": {
        "id": "QiEYUavvw_sL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install library jika belum\n",
        "!pip install annoy faiss-cpu hnswlib\n",
        "\n",
        "import numpy as np\n",
        "import time\n",
        "import pandas as pd\n",
        "from annoy import AnnoyIndex\n",
        "import faiss\n",
        "import hnswlib\n",
        "\n",
        "# ==========================================\n",
        "# Percobaan pada metric distance berbeda\n",
        "# ==========================================\n",
        "n_data = 1000000   # jumlah data\n",
        "dim = 5\n",
        "k = 10\n",
        "metrics = ['euclidean', 'angular']  # dua metric yang diuji\n",
        "hasil = []\n",
        "\n",
        "for metric in metrics:\n",
        "    print(f\"\\n=== Percobaan Metric: {metric} ===\")\n",
        "    X = np.random.random((n_data, dim)).astype(np.float32)\n",
        "    query = np.random.random((1, dim)).astype(np.float32)\n",
        "\n",
        "    # 1️⃣ Annoy\n",
        "    ann = AnnoyIndex(dim, metric)\n",
        "    start = time.time()\n",
        "    for i in range(n_data):\n",
        "        ann.add_item(i, X[i])\n",
        "    ann.build(10)\n",
        "    build_time = time.time() - start\n",
        "\n",
        "    start = time.time()\n",
        "    ann.get_nns_by_vector(query[0], k)\n",
        "    query_time = time.time() - start\n",
        "\n",
        "    hasil.append([\"Annoy\", metric, round(build_time, 4), round(query_time, 4)])\n",
        "\n",
        "    # 2️⃣ FAISS\n",
        "    if metric == 'euclidean':\n",
        "        index = faiss.IndexFlatL2(dim)\n",
        "    else:\n",
        "        index = faiss.IndexFlatIP(dim)\n",
        "        X = X / np.linalg.norm(X, axis=1, keepdims=True)\n",
        "        query = query / np.linalg.norm(query, axis=1, keepdims=True)\n",
        "\n",
        "    start = time.time()\n",
        "    index.add(X)\n",
        "    build_time = time.time() - start\n",
        "\n",
        "    start = time.time()\n",
        "    index.search(query, k)\n",
        "    query_time = time.time() - start\n",
        "\n",
        "    hasil.append([\"FAISS\", metric, round(build_time, 4), round(query_time, 4)])\n",
        "\n",
        "    # 3️⃣ HNSW\n",
        "    space = 'l2' if metric == 'euclidean' else 'cosine'\n",
        "    hnsw = hnswlib.Index(space=space, dim=dim)\n",
        "    start = time.time()\n",
        "    hnsw.init_index(max_elements=n_data, ef_construction=200, M=16)\n",
        "    hnsw.add_items(X)\n",
        "    build_time = time.time() - start\n",
        "\n",
        "    hnsw.set_ef(50)\n",
        "    start = time.time()\n",
        "    hnsw.knn_query(query, k=k)\n",
        "    query_time = time.time() - start\n",
        "\n",
        "    hasil.append([\"HNSW\", metric, round(build_time, 4), round(query_time, 4)])\n",
        "\n",
        "# ==========================================\n",
        "# Tampilkan hasil sebagai tabel\n",
        "# ==========================================\n",
        "tabel = pd.DataFrame(hasil, columns=[\"Model\", \"Metric\", \"Build Time (s)\", \"Query Time (s)\"])\n",
        "print(\"\\n=== Hasil Percobaan ===\")\n",
        "print(tabel)"
      ],
      "metadata": {
        "id": "943_bBiryMIy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kode ini membandingkan tiga algoritma pencarian tetangga terdekat — Annoy, FAISS, dan HNSW — pada dataset berukuran 1 juta data dengan 5 dimensi, menggunakan dua metric distance yaitu Euclidean dan Angular. Setiap algoritma dihitung waktu build index (pembuatan struktur data untuk pencarian) dan waktu query (proses mencari tetangga terdekat). Hasil percobaan kemudian dicatat dalam tabel agar mudah dibandingkan kecepatan dan efisiensi masing-masing metode pada metric yang berbeda."
      ],
      "metadata": {
        "id": "oTTRs_Zd1yK3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**PRAKTIKUM 5**"
      ],
      "metadata": {
        "id": "q3WrQwu210Ll"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import time\n",
        "import faiss\n",
        "from annoy import AnnoyIndex\n",
        "import hnswlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# -------------------------------\n",
        "# Dataset random\n",
        "# -------------------------------\n",
        "d = 128        # dimensi\n",
        "nb = 100000    # jumlah database vector\n",
        "nq = 1000      # jumlah query\n",
        "\n",
        "np.random.seed(42)\n",
        "xb = np.random.random((nb, d)).astype('float32')\n",
        "xq = np.random.random((nq, d)).astype('float32')\n",
        "\n",
        "# -------------------------------\n",
        "# Ground truth dengan FAISS brute force\n",
        "# -------------------------------\n",
        "index_flat = faiss.IndexFlatL2(d)\n",
        "index_flat.add(xb)\n",
        "k = 10\n",
        "_, gt_idx = index_flat.search(xq, k)\n",
        "\n",
        "# -------------------------------\n",
        "# Fungsi recall\n",
        "# -------------------------------\n",
        "def recall_at_k(I_pred, I_gt, k):\n",
        "    correct = 0\n",
        "    for i in range(len(I_pred)):\n",
        "        correct += len(set(I_pred[i][:k]) & set(I_gt[i][:k]))\n",
        "    return correct / (len(I_pred) * k)\n",
        "\n",
        "# -------------------------------\n",
        "# Benchmark Annoy\n",
        "# -------------------------------\n",
        "def run_annoy(xb, xq, n_trees=10, search_k=1000, k=10):\n",
        "    f = xb.shape[1]\n",
        "    index = AnnoyIndex(f, 'euclidean')\n",
        "    for i, v in enumerate(xb):\n",
        "        index.add_item(i, v)\n",
        "    index.build(n_trees)\n",
        "\n",
        "    start = time.time()\n",
        "    I = [index.get_nns_by_vector(v, k, search_k=search_k) for v in xq]\n",
        "    elapsed = (time.time() - start) * 1000 / len(xq)  # ms/query\n",
        "    rec = recall_at_k(I, gt_idx, k)\n",
        "    return rec, elapsed\n",
        "\n",
        "# -------------------------------\n",
        "# Benchmark FAISS IVF\n",
        "# -------------------------------\n",
        "def run_faiss(xb, xq, nlist=100, nprobe=10, k=10):\n",
        "    quantizer = faiss.IndexFlatL2(d)\n",
        "    index = faiss.IndexIVFFlat(quantizer, d, nlist, faiss.METRIC_L2)\n",
        "    index.train(xb)\n",
        "    index.add(xb)\n",
        "\n",
        "    index.nprobe = nprobe\n",
        "    start = time.time()\n",
        "    _, I = index.search(xq, k)\n",
        "    elapsed = (time.time() - start) * 1000 / len(xq)\n",
        "    rec = recall_at_k(I, gt_idx, k)\n",
        "    return rec, elapsed\n",
        "\n",
        "# -------------------------------\n",
        "# Benchmark HNSW\n",
        "# -------------------------------\n",
        "def run_hnsw(xb, xq, ef=100, M=16, k=10):\n",
        "    num_elements = xb.shape[0]\n",
        "    p = hnswlib.Index(space='l2', dim=d)\n",
        "    p.init_index(max_elements=num_elements, ef_construction=200, M=M)\n",
        "    p.add_items(xb)\n",
        "    p.set_ef(ef)\n",
        "\n",
        "    start = time.time()\n",
        "    I, _ = p.knn_query(xq, k)\n",
        "    elapsed = (time.time() - start) * 1000 / len(xq)\n",
        "    rec = recall_at_k(I, gt_idx, k)\n",
        "    return rec, elapsed\n",
        "\n",
        "# -------------------------------\n",
        "# Jalankan benchmark dengan beberapa parameter\n",
        "# -------------------------------\n",
        "results = {\"Annoy\": [], \"Faiss\": [], \"HNSW\": []}\n",
        "\n",
        "# Annoy\n",
        "for sk in [200, 500, 1000, 2000]:\n",
        "    rec, t = run_annoy(xb, xq, n_trees=10, search_k=sk)\n",
        "    results[\"Annoy\"].append((rec, t))\n",
        "\n",
        "# FAISS\n",
        "for npb in [1, 5, 10, 20]:\n",
        "    rec, t = run_faiss(xb, xq, nlist=100, nprobe=npb)\n",
        "    results[\"Faiss\"].append((rec, t))\n",
        "\n",
        "# HNSW\n",
        "for ef in [50, 100, 200, 400]:\n",
        "    rec, t = run_hnsw(xb, xq, ef=ef)\n",
        "    results[\"HNSW\"].append((rec, t))\n",
        "\n",
        "# -------------------------------\n",
        "# Visualisasi trade-off\n",
        "# -------------------------------\n",
        "plt.figure(figsize=(8,6))\n",
        "for label, color in zip(results.keys(), [\"blue\",\"green\",\"red\"]):\n",
        "    recall, qtime = zip(*results[label])\n",
        "    plt.plot(recall, qtime, marker=\"o\", label=label, color=color)\n",
        "\n",
        "plt.xlabel(\"Recall\")\n",
        "plt.ylabel(\"Query Time (ms/query, log scale)\")\n",
        "plt.yscale(\"log\")\n",
        "plt.gca().invert_yaxis()  # invert Y, makin kanan makin turun\n",
        "plt.title(\"ANN Benchmark (Annoy vs Faiss vs HNSW)\")\n",
        "plt.legend()\n",
        "plt.grid(True, which=\"both\", ls=\"--\", alpha=0.6)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "71l-Zosf13Cl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**PRAKTIKUM 6**"
      ],
      "metadata": {
        "id": "q-S8Bn0J2iNp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "import faiss\n",
        "from annoy import AnnoyIndex\n",
        "import hnswlib\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# -------------------------------\n",
        "# Load dataset\n",
        "# -------------------------------\n",
        "# Coba baca dengan pemisah koma (default)\n",
        "df = pd.read_csv('/content/drive/MyDrive/Kebutuhan smt 5/spotify_songs.csv')\n",
        "\n",
        "\n",
        "features = ['danceability', 'energy', 'loudness', 'speechiness',\n",
        "            'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo']\n",
        "X = df[features].values\n",
        "\n",
        "# Standarisasi fitur\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "k = 10  # jumlah nearest neighbors\n",
        "\n",
        "# -------------------------------\n",
        "# Exact Nearest Neighbor (brute-force)\n",
        "# -------------------------------\n",
        "start = time.time()\n",
        "nn = NearestNeighbors(n_neighbors=k, algorithm='brute', metric='euclidean')\n",
        "nn.fit(X_scaled)\n",
        "dist_exact, idx_exact = nn.kneighbors(X_scaled)\n",
        "time_exact = time.time() - start\n",
        "print(f\"Exact NN done in {time_exact:.3f} s\")\n",
        "\n",
        "# -------------------------------\n",
        "# Annoy\n",
        "# -------------------------------\n",
        "start = time.time()\n",
        "f = X_scaled.shape[1]\n",
        "index_annoy = AnnoyIndex(f, 'euclidean')\n",
        "for i, v in enumerate(X_scaled):\n",
        "    index_annoy.add_item(i, X_scaled[i])\n",
        "index_annoy.build(10)\n",
        "idx_annoy = [index_annoy.get_nns_by_vector(v, k) for v in X_scaled]\n",
        "time_annoy = time.time() - start\n",
        "print(f\"Annoy done in {time_annoy:.3f} s\")\n",
        "\n",
        "# -------------------------------\n",
        "# HNSW\n",
        "# -------------------------------\n",
        "start = time.time()\n",
        "p_hnsw = hnswlib.Index(space='l2', dim=X_scaled.shape[1])\n",
        "p_hnsw.init_index(max_elements=X_scaled.shape[0], ef_construction=200, M=16)\n",
        "p_hnsw.add_items(X_scaled)\n",
        "p_hnsw.set_ef(200)\n",
        "idx_hnsw, dist_hnsw = p_hnsw.knn_query(X_scaled, k=k)\n",
        "time_hnsw = time.time() - start\n",
        "print(f\"HNSW done in {time_hnsw:.3f} s\")\n",
        "\n",
        "# -------------------------------\n",
        "# FAISS IVF\n",
        "# -------------------------------\n",
        "start = time.time()\n",
        "quantizer = faiss.IndexFlatL2(X_scaled.shape[1])\n",
        "index_faiss = faiss.IndexIVFFlat(quantizer, X_scaled.shape[1], 100, faiss.METRIC_L2)\n",
        "index_faiss.train(X_scaled)\n",
        "index_faiss.add(X_scaled)\n",
        "index_faiss.nprobe = 10\n",
        "dist_faiss, idx_faiss = index_faiss.search(X_scaled, k)\n",
        "time_faiss = time.time() - start\n",
        "print(f\"FAISS IVF done in {time_faiss:.3f} s\")\n",
        "\n",
        "# -------------------------------\n",
        "# Contoh tampilkan top-5 neighbors dari item pertama\n",
        "# -------------------------------\n",
        "print(\"\\nTop-5 neighbors for first song:\")\n",
        "print(f\"Exact NN: {idx_exact[0][:5]}\")\n",
        "print(f\"Annoy:    {idx_annoy[0][:5]}\")\n",
        "print(f\"HNSW:     {idx_hnsw[0][:5]}\")\n",
        "print(f\"FAISS:    {idx_faiss[0][:5]}\")"
      ],
      "metadata": {
        "id": "aQl3c1DF33IE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kode asli sudah menempuh alur dasar yang benar: memuat dataset, memilih fitur numerik, melakukan normalisasi, dan menguji empat metode (Exact NN, Annoy, HNSW, FAISS). Namun ada beberapa kelemahan penting. Pertama, kode menghitung Exact NN untuk seluruh dataset (nn.kneighbors(X_scaled)) dan juga melakukan pencarian untuk semua titik di Annoy dan FAISS—ini sangat berat dan bisa menyebabkan out-of-memory atau waktu eksekusi yang sangat lama pada dataset berskala ratusan ribu hingga juta baris. Kedua, pengukuran waktu dalam kode asli menggabungkan build index dan waktu add-item dalam satu pengukuran untuk beberapa metode (mis. pada Annoy start = time.time() sebelum loop add_item → ann_index.build(10) lalu build_time = time.time() - start itu sudah benar tapi pengukuran query juga dilakukan terhadap seluruh dataset; lebih baik pisahkan). Ketiga, kode tidak mengevaluasi akurasi approximate methods terhadap ground-truth Exact NN (mis. recall@k), sehingga tidak terlihat trade-off antara kecepatan dan kualitas hasil. Keempat, ada kemungkinan masalah tipe data (FAISS mengharapkan float32) dan normalisasi saat memakai inner-product/cosine (harus normalisasi vektor sebelum menggunakan IndexFlatIP untuk cosine). Kelima, untuk FAISS IVF perlu memastikan index.train() dipanggil dengan data representatif dan nlist/nprobe di-tune."
      ],
      "metadata": {
        "id": "OgD5LYTA3o0E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TUGAS PRAKTIKUM**"
      ],
      "metadata": {
        "id": "iQn3cPqc3slM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import time\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "from annoy import AnnoyIndex\n",
        "import hnswlib\n",
        "import faiss\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# -------------------------------\n",
        "# Contoh dataset kecil untuk testing\n",
        "# -------------------------------\n",
        "np.random.seed(42)\n",
        "n_samples = 10000   # jumlah database vector\n",
        "d = 128             # dimensi\n",
        "X = np.random.random((n_samples, d)).astype('float32')\n",
        "\n",
        "# Standarisasi fitur\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "k = 10  # jumlah nearest neighbors\n",
        "\n",
        "# -------------------------------\n",
        "# Exact NN (brute-force)\n",
        "# -------------------------------\n",
        "start = time.time()\n",
        "nn = NearestNeighbors(n_neighbors=k, algorithm='brute', metric='euclidean')\n",
        "nn.fit(X_scaled)\n",
        "dist_exact, idx_exact = nn.kneighbors(X_scaled)\n",
        "time_exact = time.time() - start\n",
        "print(f\"Exact NN done in {time_exact:.3f} s\")\n",
        "\n",
        "# -------------------------------\n",
        "# Annoy\n",
        "# -------------------------------\n",
        "start = time.time()\n",
        "f = X_scaled.shape[1]\n",
        "index_annoy = AnnoyIndex(f, 'euclidean')\n",
        "for i, v in enumerate(X_scaled):\n",
        "    index_annoy.add_item(i, v)\n",
        "index_annoy.build(10)\n",
        "idx_annoy = [index_annoy.get_nns_by_vector(v, k) for v in X_scaled]\n",
        "time_annoy = time.time() - start\n",
        "print(f\"Annoy done in {time_annoy:.3f} s\")\n",
        "\n",
        "# -------------------------------\n",
        "# HNSW\n",
        "# -------------------------------\n",
        "start = time.time()\n",
        "p_hnsw = hnswlib.Index(space='l2', dim=d)\n",
        "p_hnsw.init_index(max_elements=n_samples, ef_construction=200, M=16)\n",
        "p_hnsw.add_items(X_scaled)\n",
        "p_hnsw.set_ef(200)\n",
        "idx_hnsw, _ = p_hnsw.knn_query(X_scaled, k=k)\n",
        "time_hnsw = time.time() - start\n",
        "print(f\"HNSW done in {time_hnsw:.3f} s\")\n",
        "\n",
        "# -------------------------------\n",
        "# FAISS IVF\n",
        "# -------------------------------\n",
        "start = time.time()\n",
        "quantizer = faiss.IndexFlatL2(d)\n",
        "index_faiss = faiss.IndexIVFFlat(quantizer, d, nlist=100, metric=faiss.METRIC_L2)\n",
        "index_faiss.train(X_scaled)\n",
        "index_faiss.add(X_scaled)\n",
        "index_faiss.nprobe = 10\n",
        "_, idx_faiss = index_faiss.search(X_scaled, k)\n",
        "time_faiss = time.time() - start\n",
        "print(f\"FAISS IVF done in {time_faiss:.3f} s\")\n",
        "\n",
        "# -------------------------------\n",
        "# Tampilkan ringkasan waktu\n",
        "# -------------------------------\n",
        "print(\"\\n=== Ringkasan Waktu (detik) ===\")\n",
        "print(f\"Exact NN : {time_exact:.3f}\")\n",
        "print(f\"Annoy    : {time_annoy:.3f}\")\n",
        "print(f\"HNSW     : {time_hnsw:.3f}\")\n",
        "print(f\"FAISS    : {time_faiss:.3f}\")"
      ],
      "metadata": {
        "id": "w9ydiynY2SUU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}